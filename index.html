<!DOCTYPE html>
<html>
<head>
    <meta charset="utf-8">
    <meta name="description"
          content="Joint Video Super-Resolution (SR) and Deblurring.">
    <meta name="keywords" content="Super-Resolution, Deblurring, SR, VSRDB, FMA-Net">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <title>SkateFormer: Skeletal-Temporal Transformer for Human Action Recognition</title>
    <style>
    @keyframes shake {
      0% {transform: translateX(0);}
      10%, 90% {transform: translateX(-5px);}
      20%, 80% {transform: translateX(5px);}
      30%, 50%, 70% {transform: translateX(-5px);}
      40%, 60% {transform: translateX(5px);}
      100% {transform: translateX(0);}
    }

    #blur {
      /* font-size: 60px; */
      color: rgb(52,144,197);
      filter: blur(3x);
      -webkit-filter: blur(2.5px);
      animation: shake 1s infinite;
      display: inline-block;;
      clear: none;
    }
    #shake {
      /* font-size: 60px; */
      animation: shake 1s infinite;
      display: inline-block;;
      clear: none;
    }

    </style>

    <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro">
    <link rel="stylesheet" href="./static/css/bulma.min.css">
    <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
    <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
    <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
    <link rel="stylesheet" href="./static/css/index.css">
    <link rel="icon" sizes="256x256" href="./static/image/skate.png" type="image/png"/>

    <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
    <script defer src="./static/js/fontawesome.all.min.js"></script>
    <script src="./static/js/bulma-carousel.min.js"></script>
    <script src="./static/js/bulma-slider.min.js"></script>
    <script src="./static/js/index.js"></script>
    <script src="./static/js/video_comparison.js"></script>
</head>
<body>

<nav class="navbar" role="navigation" aria-label="main navigation">
    <div class="navbar-brand">
        <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
            <span aria-hidden="true"></span>
            <span aria-hidden="true"></span>
            <span aria-hidden="true"></span>
        </a>
    </div>
</nav>


<section class="hero">
    <div class="hero-body">
        <div class="container is-max-desktop">
            <div class="columns is-centered">
                <div class="column has-text-centered">
                    <div class="title is-2 publication-title"><h1 style="display: inline; clear:none;"><img
                            src="./static/image/skate.png" width="40" , height="40"><font
                            color="#d91421"><b>Ska</b></font><font color="#1484d9"><b>te</b></font><b>Former</b>: <font
                            color="#d91421"><b>Sk</b></font>elet<font color="#d91421"><b>a</b></font>l-<font
                            color="#1484d9"><b>Te</b></font>mporal Trans<b>former</b> for Human Action Recognition</h1>
                    </div>
                    <div class="is-size-5 publication-authors">
                        <span class="author-block">This page is under reconstruction</span>
                    </div>
                    <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a target="_blank" rel="noopener noreferrer" href="https://sites.google.com/view/jeonghyeokdo/">Jeonghyeok Do</a>&nbsp;&nbsp;&nbsp;&nbsp;
	        </span>
                        <span class="author-block">
              <a target="_blank" rel="noopener noreferrer" href="https://www.viclab.kaist.ac.kr/">Munchurl Kim</a>
            </span>
                    </div>

                    <div class="is-size-5 publication-authors">
                        <span class="author-block">Korea Advanced Institute of Science and Technology, South Korea</span>
                        &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
                    </div>

                </div>

            </div>
        </div>
    </div>
    </div>
    </div>
</section>

<!-- Motivation. -->
<section class="section">
    <div class="container is-max-desktop">
        <h2 class="title is-3">Motivation</h2>
        <image src="./static/image/motiv.png"><br>
            <div class="content has-text-justified">
                <p>
                    <b>SkateFormer's partition-specific attention strategy.</b> SkateFormer partitions joints and frames
                    based on different types of skeletal-temporal relation (4 Skate-Types) and performs
                    skeletal-temporal self-attention (Skate-MSA) within each partition.
                </p>
            </div>

    </div>
</section>

<!-- Abstract. -->
<section class="section">
    <div class="container is-max-desktop">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
            <p>
                We propose a Skeletal-Temporal Transformer (SkateFormer), a partition-specific attention strategy
                (Skate-MSA) for skeleton-based action recognition that captures skeletal-temporal relations and reduces
                computational complexity.
            </p>
            <p>
                We introduce a range of augmentation techniques and an effective positional embedding method, named
                Skate-Embedding, which combines skeletal and temporal features.
                This method significantly enhances action recognition performance by forming an outer product between
                learnable skeletal features and fixed temporal index features.
            </p>
            <p>
                Our SkateFormer sets a new state-of-the-art for action recognition performance across multiple
                modalities
                (4-ensemble condition) and single modalities (joint, bone, joint motion, bone motion), showing notable
                improvement over the most recent state-of-the-art methods.
                Additionally, it concurrently establishes a new state-of-the-art in interaction recognition, a sub-field
                of
                action recognition.
            </p>
        </div>
    </div>

</section>


<footer class="footer">
    <div class="container">
        <div class="content has-text-centered">
            <a target="_blank" rel="noopener noreferrer" class="icon-link"
               href="">
                <i class="fas fa-file-pdf"></i>
            </a>
            <a target="_blank" rel="noopener noreferrer" class="icon-link" href="https://github.com/KAIST-VICLab"
               class="external-link" disabled>
                <i class="fab fa-github"></i>
            </a>
        </div>
        <div class="columns is-centered">
            <div class="column is-8">
                <div class="content">
                    <p>
                        We thank the authors of <a target="_blank" rel="noopener noreferrer"
                                                   href="https://github.com/nerfies/nerfies.github.io">Nerfies</a> that
                        kindly open sourced the template of this website.
                        Please visit our <a target="_blank" rel="noopener noreferrer"
                                            href="https://github.com/KAIST-VICLab">VIC-Lab</a> for more interesting
                        researches
                    </p>
                </div>
            </div>
</footer>
</body>
</html>
